{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c815ebf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pathos'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmath\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmultiprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ProcessingPool \u001b[38;5;28;01mas\u001b[39;00m Pool\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mjson\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pathos'"
     ]
    }
   ],
   "source": [
    "import math\n",
    "from pathos.multiprocessing import ProcessingPool as Pool\n",
    "import time\n",
    "import json\n",
    "\n",
    "import distribution_tools as tools\n",
    "import numpy as np\n",
    "from functools import partial\n",
    "\n",
    "# Graph Initialisation\n",
    "N_nodes: int = 100\n",
    "N_experts: int = 100\n",
    "# Number of runs for each parameter\n",
    "n_runs = 5\n",
    "\n",
    "# Create a set of initial distributions\n",
    "initial_opinions = []\n",
    "\n",
    "def create_initial_distribution(N_experts, N_total):\n",
    "    array = np.empty(N_total)\n",
    "    array[:N_experts] = np.random.uniform(size=N_experts)\n",
    "    array[N_experts:] = np.nan\n",
    "    np.random.shuffle(array)\n",
    "    return array\n",
    "\n",
    "def evenly_spaced_initial_conditions(N_experts, N_total):\n",
    "    array = np.empty(N_total)\n",
    "    # Generate N equally spaced values between 0 and 1\n",
    "    # array[:N_experts] = np.linspace(0, 1, N_experts)\n",
    "    array[:N_experts] = np.repeat(np.linspace(0, 1, int(N_experts/5)), 5)\n",
    "    array[N_experts:] = np.nan\n",
    "    np.random.shuffle(array)\n",
    "    return array\n",
    "\n",
    "for sigma in range(n_runs):\n",
    "    distribution = create_initial_distribution(N_experts, N_nodes)\n",
    "    initial_opinions.append(distribution)\n",
    "\n",
    "# show_distribution(initial_opinions[10])\n",
    "# print('done')\n",
    "\n",
    "# Create a set of parameter intervals\n",
    "intervals = [(1, 1.5), (1.5, 1.75), (1.75, 2), (2, 2.25), (2.25, 2.5), (2.5, 2.75), (2.75, 3),\n",
    "             (3, 3.25), (3.25, 3.5), (3.5, 3.75), (3.75, 4)]\n",
    "step = 0.1\n",
    "\n",
    "parameter_range = []\n",
    "for interval in intervals:\n",
    "    start, end = interval\n",
    "    size = math.ceil((end - start) / step)\n",
    "    deltas = np.linspace(start, end, num=size, endpoint=False)\n",
    "    epsilons = 0.5 / deltas\n",
    "    parameter_range.append(epsilons)\n",
    "\n",
    "\n",
    "def one_iteration(N_nodes, initial_opinions, parameter_range, index):\n",
    "    from simulation import Simulation\n",
    "    from deffuant_barabasi_class import DeffuantBarabasiModel\n",
    "\n",
    "    def run(parameter, initial_value):\n",
    "        # Initiate a model with confidence bound specified in parameter\n",
    "        confidence_bound, cautiousness = parameter, 0.5\n",
    "        model = DeffuantBarabasiModel(N_nodes, confidence_bound, cautiousness)\n",
    "        # Set initial condition\n",
    "        model.set_opinion(initial_value)\n",
    "        # Run opinion formation on the model\n",
    "        model.opinion_formation()\n",
    "        # if model converged to return opinion if not to return []\n",
    "        if model.get_opinion():\n",
    "            # Identify clusters and their means\n",
    "            clusters, means = model.clusters_detector(model.get_opinion())\n",
    "            # Calculate clusters densities\n",
    "            densities = model.cluster_density(clusters)\n",
    "            # Add results to data\n",
    "            result = []\n",
    "            for count, mean_value in enumerate(means):\n",
    "                density = densities[count]\n",
    "                result.append([mean_value, density])\n",
    "\n",
    "        else:\n",
    "            return []\n",
    "\n",
    "        return result\n",
    "\n",
    "    def initial_values_iterator():\n",
    "        return initial_opinions\n",
    "\n",
    "    # we split work between processes by parameter\n",
    "    # index is a process specific part of the job\n",
    "    def parameter_iterator():\n",
    "        return parameter_range[index]\n",
    "\n",
    "    generator = Simulation(parameter_iterator, initial_values_iterator, run)\n",
    "\n",
    "    return generator.run()\n",
    "\n",
    "\n",
    "def unpack(lists):\n",
    "    merged_lists = {**lists[0], **lists[1], **lists[2], **lists[3], **lists[4], **lists[5], **lists[6],\n",
    "                    **lists[7], **lists[8], **lists[9], **lists[10]}\n",
    "    return merged_lists\n",
    "\n",
    "\n",
    "total_cores = 6\n",
    "p = Pool(total_cores)\n",
    "t0 = time.time()\n",
    "\n",
    "f = partial(one_iteration, N_nodes, initial_opinions, parameter_range)\n",
    "\n",
    "try:\n",
    "    experiments = unpack(p.map(f, range(len(intervals))))\n",
    "finally:\n",
    "    p.terminate()\n",
    "\n",
    "t1 = time.time()\n",
    "convergence_time = t1-t0\n",
    "print(\"performance time\", convergence_time)\n",
    "\n",
    "# # Writing to json\n",
    "# data = {'setup': {'N_nodes': N_nodes,\n",
    "#                   'step': step,\n",
    "#                   'notes': 'polar model with uniform IC',\n",
    "#                   'convergence_time': convergence_time},\n",
    "#         'experiments': experiments,\n",
    "#         'initial_conditions': [r.tolist() for r in initial_opinions]\n",
    "#         }\n",
    "\n",
    "# filename = '/Users/daxelka/Research/Deffuant_model/Deffuant-Barabasi/biff_DB_1000_evenly_spaced_repeated_5.txt'\n",
    "\n",
    "# with open(filename, 'w') as outfile:\n",
    "#     json.dump(data, outfile)\n",
    "# print('json created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af20868",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
